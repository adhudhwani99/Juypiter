{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    id  room_id/id        noted_date  temp  \\\n",
      "0  __export__.temp_log_196134_bd201015  Room Admin  08-12-2018 09:30  29.0   \n",
      "1  __export__.temp_log_196131_7bca51bc  Room Admin  08-12-2018 09:30  29.0   \n",
      "2  __export__.temp_log_196127_522915e3  Room Admin  08-12-2018 09:29  41.0   \n",
      "3  __export__.temp_log_196128_be0919cf  Room Admin  08-12-2018 09:29  41.0   \n",
      "4  __export__.temp_log_196126_d30b72fb  Room Admin  08-12-2018 09:29  31.0   \n",
      "\n",
      "  out/in  \n",
      "0     In  \n",
      "1     In  \n",
      "2    Out  \n",
      "3    Out  \n",
      "4     In  \n"
     ]
    }
   ],
   "source": [
    "#We are going to import from Pandas,Numpy, and sklearn and store the data frame into the variable df [18BIS0103]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"IOT-temp dataset task 2.csv\")\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         noted_date  temp out/in\n",
      "0  08-12-2018 09:30  29.0     In\n",
      "1  08-12-2018 09:30  29.0     In\n",
      "2  08-12-2018 09:29  41.0    Out\n",
      "3  08-12-2018 09:29  41.0    Out\n",
      "4  08-12-2018 09:29  31.0     In\n"
     ]
    }
   ],
   "source": [
    "#We are going to Drop the coloums that are not required for pridiction [18BIS0103]\n",
    "#These coloums are id, and room_id/id \n",
    "\n",
    "df_dropped = df.drop(columns=[\"id\",\"room_id/id\"])\n",
    "print(df_dropped.head())\n",
    "\n",
    "#The coloums show below the coloums droppped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97606, 3)\n"
     ]
    }
   ],
   "source": [
    "#These are the values that contain duplicated values\n",
    "print(df_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37281\n"
     ]
    }
   ],
   "source": [
    "#We are going to Remove duplicate values\n",
    "df_dropped.drop_duplicates(inplace=True)\n",
    "df_dropped[df_dropped.duplicated()]\n",
    "entries=df_dropped.shape\n",
    "entries = int(entries[0])\n",
    "print(entries)\n",
    "#We also stored the number of entries for later use\n",
    "#These are the number of rows after the duplicated values are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noted_date     0\n",
      "temp          14\n",
      "out/in         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_dropped.isnull().sum())\n",
    "\n",
    "#We can see that there are 14 null values in temp coloum. We can put the mean value there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noted_date    0\n",
      "temp          0\n",
      "out/in        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We are going to remove the missing data and put in the MEAN value\n",
    "\n",
    "missing_value = ['temp']\n",
    "\n",
    "for column in missing_value:\n",
    "    df_dropped[column] = df_dropped[column].replace(np.NaN, np.NaN)\n",
    "    mean = int(df_dropped[column].mean(skipna=True))\n",
    "    df_dropped[column] = df_dropped[column].replace(np.NaN, mean)\n",
    "    \n",
    "print(df_dropped.isnull().sum())\n",
    "\n",
    "#The below is a proof that the Data is free of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noted_date    0\n",
      "temp          0\n",
      "out/in        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#NOTE : THIS IS THE SAME STEP AS THE PREVIOUS ONE, EXECPT WE USE MEDIAN VALUE\n",
    "#We are going to remove the missing data and put in the median value\n",
    "\n",
    "missing_value = ['temp']\n",
    "\n",
    "for column in missing_value:\n",
    "    df_dropped[column] = df_dropped[column].replace(np.NaN, np.NaN)\n",
    "    median = int(df_dropped[column].median(skipna=True))\n",
    "    df_dropped[column] = df_dropped[column].replace(np.NaN, median)\n",
    "    \n",
    "print(df_dropped.isnull().sum())\n",
    "\n",
    "#The below is a proof that the Data is free of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            noted_date  temp out/in\n",
      "0  1544261400000000000  29.0     In\n",
      "2  1544261340000000000  41.0    Out\n",
      "4  1544261340000000000  31.0     In\n",
      "6  1544261280000000000  29.0     In\n",
      "8  1544261160000000000  29.0     In\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37281 entries, 0 to 97603\n",
      "Data columns (total 3 columns):\n",
      "noted_date    37281 non-null int64\n",
      "temp          37281 non-null float64\n",
      "out/in        37281 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Complete the call to convert the date column\n",
    "df_dropped['noted_date'] =  pd.to_datetime(df_dropped['noted_date'], format='%d-%m-%Y %H:%M')\n",
    "df_dropped['noted_date'].astype('datetime64[D]').dtype\n",
    "df_dropped['noted_date'] = pd.to_numeric(pd.to_datetime(df_dropped['noted_date']))\n",
    "# Confirm the date column is in datetime format\n",
    "print(df_dropped.head())\n",
    "print(df_dropped.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             noted_date  temp out/in\n",
      "2   1544261340000000000  41.0    Out\n",
      "10  1544261100000000000  42.0    Out\n",
      "16  1544260860000000000  41.0    Out\n",
      "20  1544260740000000000  42.0    Out\n",
      "24  1544260620000000000  41.0    Out\n",
      "             noted_date  temp out/in\n",
      "0   1544261400000000000  29.0     In\n",
      "4   1544261340000000000  31.0     In\n",
      "6   1544261280000000000  29.0     In\n",
      "8   1544261160000000000  29.0     In\n",
      "12  1544261040000000000  29.0     In\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into out and in\n",
    " \n",
    "df_dropped_out = df_dropped[df_dropped['out/in'] =='Out'] #This Varialble has OUT in it\n",
    "df_dropped_in = df_dropped[df_dropped['out/in'] =='In'] #This variable has IN in it\n",
    "\n",
    "print(df_dropped_out.head())\n",
    "print(df_dropped_in.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset for training and testing for OUT --> 1 for out, 2 --> IN\n",
    "\n",
    "X1 = df_dropped_out.iloc[:, 0:2]\n",
    "y1 = df_dropped_out.iloc[:, 1]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1,y1,random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset for training and testing for IN --> 1 for out, 2 for in\n",
    "\n",
    "X2 = df_dropped_in.iloc[:, 0:2]\n",
    "y2 = df_dropped_in.iloc[:, 1]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2,y2,random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "sc_X1 = StandardScaler()\n",
    "X1_train = sc_X1.fit_transform(X1_train)\n",
    "X1_test = sc_X1.transform(X1_test)\n",
    "sc_X2 = StandardScaler()\n",
    "X2_train = sc_X2.fit_transform(X2_train)\n",
    "X2_test = sc_X2.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import math\n",
    "#math.sqrt(len(y1_test))\n",
    "classifier_IN = KNeighborsClassifier(n_neighbors= 3, p = 2, metric = 'euclidean')\n",
    "classifier_IN.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p='weighted',\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_OUT = KNeighborsClassifier(n_neighbors= 3, p = 'weighted', metric = 'euclidean')\n",
    "classifier_OUT.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  19   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 139   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1 256   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 203   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 239   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 139   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 141   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1 129   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0 230   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 318   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 324   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 387   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 346   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 414\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  317   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 272   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 291   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 236   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 228   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 172   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1 190   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   4  81   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   1   0]]\n",
      "0.9973435734793673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dhudhwani\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y1_pred = classifier_OUT.predict(X1_test)\n",
    "y2_pred = classifier_IN.predict(X2_test)\n",
    "cm = confusion_matrix (y1_test,y1_pred)\n",
    "print (cm)\n",
    "print (f1_score(y1_test,y1_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   5   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  18   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  40   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 113   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 156   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 300   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 282   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 331   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 291   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 232   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 152   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  60   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8]]\n",
      "0.9996649916247907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dhudhwani\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cm_in = confusion_matrix(y2_test, y2_pred)\n",
    "print (cm_in)\n",
    "print (f1_score(y2_test, y2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
